{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression as lir\n",
    "import pickle as pk\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '/mnt/c/Users/Abhinav/Documents/Semester_7/BTP - 1/Avg_NL_Dist_cf_cvg.csv'\n",
    "districts_path = '/mnt/c/Users/Abhinav/Documents/Semester_7/BTP - 1/Data/districts.csv'\n",
    "district = \"Allahabad\"\n",
    "years = 6\n",
    "Isoutput = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(raw_data_path,header=None)\n",
    "df = df.T\n",
    "data = 0\n",
    "def take(x):\n",
    "    global data\n",
    "    data = x\n",
    "df.apply(lambda x: take(x) if x[74]==district else x)\n",
    "data = data.reindex()\n",
    "data = data[1:len(data)-3]\n",
    "xaxis = np.arange(4,years*12+4)\n",
    "data = np.array(data, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpikeDates(temp):\n",
    "    arr = []\n",
    "    for i in temp:\n",
    "        mm = (i+3)%12 + 1\n",
    "        yy = 12 + int(i/12)\n",
    "        if (i%12)+3 >= 12:\n",
    "            yy += 1\n",
    "        arr.append(str(mm)+\"-20\"+str(yy))\n",
    "    return arr\n",
    "    \n",
    "def getAnnualDates(temp, month):\n",
    "    arr = []\n",
    "    for i in temp:\n",
    "        mm = (month+3)%12 + 1\n",
    "        yy = 12 + i\n",
    "        if (month%12)+3 >= 12:\n",
    "            yy += 1\n",
    "        arr.append(str(mm)+\"-20\"+str(yy))\n",
    "    return arr\n",
    "\n",
    "def intersection(a1, a2):\n",
    "    a3 = []\n",
    "    for x in a1:\n",
    "        if x in a2:\n",
    "            a3.append(x)\n",
    "    return sorted(a3, key=lambda x: (int(x.split('-')[1]), int(x.split('-')[0])))\n",
    "\n",
    "# MAD\n",
    "def outliers_modified_z_score(ys, threshold):\n",
    "    median_y = np.median(ys)\n",
    "    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y\n",
    "                         for y in ys]\n",
    "    new1 = np.where(np.abs(modified_z_scores) > threshold)\n",
    "    return new1[0]\n",
    "\n",
    "# IQR\n",
    "def outliers_iqr(noise, temp1):\n",
    "    # obj = sp.outliers_gesd(noise, outliers = 20, report = True, alpha = 0.02)\n",
    "    obj = sp.outliers_iqr(noise, coef=temp1) #return_ = 'outliers', \n",
    "    z = 0\n",
    "    arr = []\n",
    "    for i in range(len(noise)):\n",
    "        if obj[z] == noise[i]:\n",
    "            z += 1\n",
    "        else:\n",
    "            arr.append(i)\n",
    "    return arr\n",
    "\n",
    "# Z_SCORE\n",
    "def outliers_z_score(noise, influence, threshold):\n",
    "    values = noise\n",
    "    anomaly = np.zeros((12,years))\n",
    "    curmean = 0.0\n",
    "    curdev = 0.0\n",
    "    newel = 0.0\n",
    "    mean_for = []\n",
    "    mean_back = []\n",
    "    std_for = []\n",
    "    std_back = []\n",
    "    thresh = []\n",
    "    abs_val = []\n",
    "    curlen = 1\n",
    "    win = 12\n",
    "\n",
    "    mean_for.append(values[0])\n",
    "    std_for.append(0.0)\n",
    "    for i in range(1,len(values)):\n",
    "        if abs(values[i]-curmean)>curdev*threshold:\n",
    "            newel = influence*values[i]+(1-influence)*values[(i-1)]\n",
    "        else:\n",
    "            newel = values[i]\n",
    "        sum1 = newel\n",
    "        for j in range(max(0,i-win+1),i):\n",
    "            sum1 += values[j]\n",
    "        temp_mean = sum1/(min(win, i+1))\n",
    "        sum1 = (newel - temp_mean)**2\n",
    "        for j in range(max(0,i-win+1),i):\n",
    "            sum1 += (values[j] - temp_mean)**2\n",
    "        temp_std = math.sqrt(sum1/(min(win, i+1)))\n",
    "        curmean = temp_mean\n",
    "        curdev = temp_std\n",
    "        mean_for.append(temp_mean)\n",
    "        std_for.append(temp_std)\n",
    "\n",
    "    mean_back.append(values[len(values)-1])\n",
    "    std_back.append(0.0)\n",
    "    curmean=0.0\n",
    "    curdev=0.0\n",
    "    for i in range(len(values)-2,-1,-1):\n",
    "        if abs(values[i]-curmean)>curdev*threshold:\n",
    "            newel = influence*values[i]+(1-influence)*values[(i+1)]\n",
    "        else:\n",
    "            newel = values[i]\n",
    "        sum1 = newel\n",
    "        for j in range(i+1,min(len(values),i+win)):\n",
    "            sum1 += values[j]\n",
    "        temp_mean = sum1/(min(win, len(values)-i))\n",
    "        sum1 = (newel - temp_mean)**2\n",
    "        for j in range(i+1,min(len(values),i+win)):\n",
    "            sum1 += (values[j] - temp_mean)**2\n",
    "        temp_std = math.sqrt(sum1/(min(win, len(values)-i)))\n",
    "        curmean = temp_mean\n",
    "        curdev = temp_std\n",
    "        mean_back.append(temp_mean)\n",
    "        std_back.append(temp_std)\n",
    "\n",
    "    avg_mean = [mean_for[i]/2 + mean_back[len(values)-1-i]/2 for i in range(0,len(values))]\n",
    "    avg_std = [std_for[i]/2 + std_back[len(values)-1-i]/2 for i in range(0,len(values))]\n",
    "\n",
    "    for i in range(0,len(values)):\n",
    "        thresh.append(avg_std[i]*threshold)\n",
    "        abs_val.append(abs(values[i]-avg_mean[i]))\n",
    "        if abs(values[i]-avg_mean[i])>avg_std[i]*threshold:\n",
    "            anomaly[int(i%12)][int(i/12)]=1\n",
    "    \n",
    "    arr_res = []\n",
    "    if(Isoutput):\n",
    "        plt.figure(figsize=(10,12))\n",
    "    for i in range(years):\n",
    "        for j in range(12):\n",
    "            if anomaly[j][i] == 1:\n",
    "                tt = i*12 + j\n",
    "                arr_res.append(tt)\n",
    "                if(Isoutput):\n",
    "                    plt.plot(tt+1, abs_val[tt], 'o', color='black')\n",
    "\n",
    "    xaxis = np.arange(1,years*12+1)\n",
    "    if(Isoutput):\n",
    "        plt.plot(xaxis,list((thresh)))\n",
    "        plt.plot(xaxis,list((abs_val)))\n",
    "        for i in range(1,4):\n",
    "            plt.axhline(y=i*np.mean(abs_val), color='r', linestyle='-')\n",
    "    \n",
    "    return arr_res\n",
    "\n",
    "def find_anomalies_spike(noise, maxa, b1, b2, b3):\n",
    "    global influence\n",
    "    error = 0.001\n",
    "    temp = []\n",
    "    finalres = [\"$\"]\n",
    "\n",
    "    if b1 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = outliers_modified_z_score(noise, mid)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        finalres = getSpikeDates(temp)\n",
    "    \n",
    "    if b2 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = outliers_iqr(noise, mid)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = getSpikeDates(temp)\n",
    "        else:\n",
    "            finalres = intersection(finalres, getSpikeDates(temp))\n",
    "    \n",
    "    if b3 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = outliers_z_score(noise, influence, mid)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = getSpikeDates(temp)\n",
    "        else:\n",
    "            finalres = intersection(finalres, getSpikeDates(temp))\n",
    "    \n",
    "    if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = []\n",
    "    return finalres\n",
    "\n",
    "def find_anomalies_annual(noise, maxa, b1, b2, b3):\n",
    "    global influence1\n",
    "    error = 0.001\n",
    "    temp = []\n",
    "    finalres = [\"$\"]\n",
    "\n",
    "    if b1 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = []\n",
    "            for ii in range(12):\n",
    "                tempnoise = [noise[ii + j*12] for j in range(years)]\n",
    "                temp += getAnnualDates(outliers_modified_z_score(tempnoise, mid), ii)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        finalres = temp\n",
    "    \n",
    "    if b2 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        temp = []\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = []\n",
    "            for ii in range(12):\n",
    "                tempnoise = [noise[ii + j*12] for j in range(years)]\n",
    "                temp += getAnnualDates(outliers_iqr(tempnoise, mid), ii)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = temp\n",
    "        else:\n",
    "            finalres = intersection(finalres, temp)\n",
    "    \n",
    "    if b3 > 0:\n",
    "        low = 0.001\n",
    "        high = 20.0\n",
    "        while (high - low) > error:\n",
    "            mid = (low+high)/2\n",
    "            temp = outliers_z_score(noise, influence1, mid)\n",
    "            if (len(temp)) > maxa:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = temp\n",
    "        else:\n",
    "            finalres = intersection(finalres, temp)\n",
    "    \n",
    "    if len(finalres) > 0 and finalres[0] == \"$\":\n",
    "            finalres = []\n",
    "    return finalres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend\n",
    "xaxis = np.arange(4,years*12+4)\n",
    "yaxis = np.array(data[0:].tolist(),dtype=np.float32)\n",
    "\n",
    "# Detrend 1 use regression line method\n",
    "X = [i for i in range(0, len(yaxis))]\n",
    "X = np.reshape(X, (len(X), 1))\n",
    "y = yaxis\n",
    "model = lir()\n",
    "model.fit(X, y)\n",
    "# calculate trend\n",
    "yaxis1 = model.predict(X)\n",
    "\n",
    "# Detrend 2\n",
    "yaxis2 = [yaxis[i]-yaxis1[i] for i in range(0,len(yaxis))]\n",
    "\n",
    "# Detrend 3\n",
    "yaxis3=[]\n",
    "for i in range(len(yaxis2)):\n",
    "    sum1=0\n",
    "    for j in range(years):\n",
    "        sum1+=yaxis2[i%12+12*j]\n",
    "    yaxis3.append(sum1/years)\n",
    "\n",
    "noise = [yaxis[i]-yaxis1[i]-yaxis3[i] for i in range(len(yaxis))]\n",
    "\n",
    "if(Isoutput):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot(xaxis,data,marker='o', color='b')\n",
    "    plt.plot(xaxis,np.array(yaxis3)+np.array(yaxis1), color='r', linestyle='--')\n",
    "    # plt.plot(xaxis,np.array(yaxis31), color='g', linestyle='--')\n",
    "    for j in range(int((years*12)/5)):\n",
    "        plt.axvline(x=j*5,linestyle='--')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot(0,np.min(np.array(yaxis)))\n",
    "    plt.plot(0,np.max(np.array(yaxis)))\n",
    "    plt.plot(xaxis,noise,marker='o', color='b')\n",
    "    plt.axhline(y=0,linestyle='--',color='r')\n",
    "    for j in range(int((years*12)/5)):\n",
    "        plt.axvline(x=j*5,linestyle='--')\n",
    "\n",
    "noise = np.array(noise)\n",
    "noise = (noise - noise.mean(axis=0))/(noise.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: 1-2015\n",
      "Rank 2: 10-2013\n",
      "Rank 3: 9-2014\n",
      "Rank 4: 12-2016\n",
      "Rank 5: 1-2013\n",
      "Rank 6: 9-2016\n",
      "Rank 7: 6-2013\n",
      "Rank 8: 12-2013\n",
      "Rank 9: 6-2012\n",
      "Rank 10: 4-2014\n",
      "Rank 11: 6-2016\n"
     ]
    }
   ],
   "source": [
    "max_anomalies = 13\n",
    "influence = 0.2\n",
    "\n",
    "tset = set()\n",
    "res = []\n",
    "for x in range(1, max_anomalies+1):\n",
    "    temp = find_anomalies_spike(noise, x, 1, 1, 1)\n",
    "    tt = []\n",
    "    for y in temp:\n",
    "        if y not in tset:\n",
    "            tset.add(y)\n",
    "            tt.append(y)\n",
    "    if len(tt) > 0:\n",
    "        res.append(tt)\n",
    "\n",
    "z=1\n",
    "for x in res:\n",
    "    for y in x:\n",
    "        ss = 'Rank ' + str(z) + ': ' + y\n",
    "        z += 1\n",
    "        print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: 4-2014\n",
      "Rank 2: 10-2013\n",
      "Rank 3: 9-2014\n",
      "Rank 4: 1-2015\n",
      "Rank 5: 4-2016\n",
      "Rank 6: 2-2014\n",
      "Rank 7: 3-2013\n",
      "Rank 8: 11-2015\n"
     ]
    }
   ],
   "source": [
    "max_anomalies1 = 8\n",
    "influence1 = 0.2\n",
    "\n",
    "tset = set()\n",
    "res1 = []\n",
    "for x in range(1, max_anomalies1+1):\n",
    "    temp = find_anomalies_annual(noise, x, 1, 1, 0)\n",
    "    tt = []\n",
    "    for y in temp:\n",
    "        if y not in tset:\n",
    "            tset.add(y)\n",
    "            tt.append(y)\n",
    "    if len(tt) > 0:\n",
    "        res1.append(tt)\n",
    "\n",
    "z=1\n",
    "for x in res1:\n",
    "    for y in x:\n",
    "        ss = 'Rank ' + str(z) + ': ' + y\n",
    "        z += 1\n",
    "        print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
